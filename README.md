# 🔍 Interpreting Medical AI Models with GradCAM and SHAP

### 📍 Course Project – *AI for Medical Treatment* by DeepLearning.AI on Coursera

This project applies model interpretation techniques to deep learning and traditional ML models in medical diagnosis.

---

## 🧠 Key Concepts Practiced

- ✅ **GradCAM** for interpreting CNN predictions on chest X-rays
- ✅ **SHAP values** to understand feature contributions in machine learning models
- ✅ **Permutation importance** for evaluating non-deep models
- ✅ Visualization and explanation of individual predictions
- ✅ Interpretation of learned behavior in medical imaging

---

## 📊 What It Does

- Loads and visualizes predictions from a pretrained CNN (DenseNet121)
- Uses **GradCAM** to highlight image regions influencing the model
- Applies **SHAP** and **permutation importance** on tabular models
- Evaluates feature contributions for models predicting patient outcomes

---

## 🛠️ Libraries & Tools Used

- TensorFlow / Keras
- SHAP
- NumPy / Pandas
- Matplotlib / Seaborn
- Lifelines (for C-index)
- scikit-learn

---

## ⚠️ Disclaimer

> 📌 This project is based on the Coursera course:  
> [AI for Medical Treatment – by DeepLearning.AI](https://www.coursera.org/learn/ai-for-medical-treatment)  
> It is shared **for educational and portfolio use only**.  
> **Please do not plagiarize or submit it as your own work**.

---

## 📸 Example Outputs (optional if added to repo)
- GradCAM overlays showing diagnostic image regions
- SHAP plots for feature-level contribution
- Bar plots of permutation importance
